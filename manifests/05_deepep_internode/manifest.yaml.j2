---
apiVersion: v1
kind: Service
metadata:
  name: deepep-internode-master-{{ test_id }}
  labels:
    app: deepep-internode-test
    test-id: "{{ test_id }}"
spec:
  clusterIP: None
  selector:
    app: deepep-internode-test
    role: master
    test-id: "{{ test_id }}"
  ports:
  - port: 29500
    name: dist
---
apiVersion: batch/v1
kind: Job
metadata:
  name: deepep-internode-master-{{ test_id }}
  labels:
    app: deepep-internode-test
    role: master
    test-id: "{{ test_id }}"
spec:
  template:
    metadata:
      labels:
        app: deepep-internode-test
        role: master
        test-id: "{{ test_id }}"
    spec:
      restartPolicy: Never
      nodeSelector:
        kubernetes.io/hostname: "{{ server_node.name }}"
      containers:
      - name: deepep-internode-master
        image: {{ image }}
        command: ["/bin/bash"]
        args:
        - -c
        - |
          set -e
          echo "Starting DeepEP internode test (MASTER) on node {{ server_node.name }}"

          echo "GPU information:"
          nvidia-smi -L

          GPU_COUNT=$(nvidia-smi -L | wc -l)
          echo "Detected $GPU_COUNT GPUs"

          echo "Cloning DeepEP repository..."
          cd /tmp
          git clone https://github.com/deepseek-ai/DeepEP || echo "Repository already exists"
          cd DeepEP

          echo "Running DeepEP internode test with $GPU_COUNT processes per node, 2 nodes total..."
          export MASTER_ADDR=deepep-internode-master-{{ test_id }}
          export MASTER_PORT=29500
          export WORLD_SIZE=2

          python tests/test_internode.py --num-processes $GPU_COUNT --num-tokens 512 --hidden 1024 --num-topk 4 --num-experts 32

          echo "DeepEP internode test completed successfully"
        resources:
          requests:
            {{ rdma_resource_type }}: "1"
            nvidia.com/gpu: "{{ gpu_count }}"
            memory: 32Gi
            cpu: "16"
          limits:
            {{ rdma_resource_type }}: "1"
            nvidia.com/gpu: "{{ gpu_count }}"
            memory: 64Gi
            cpu: "32"
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
---
apiVersion: batch/v1
kind: Job
metadata:
  name: deepep-internode-worker-{{ test_id }}
  labels:
    app: deepep-internode-test
    role: worker
    test-id: "{{ test_id }}"
spec:
  template:
    metadata:
      labels:
        app: deepep-internode-test
        role: worker
        test-id: "{{ test_id }}"
    spec:
      restartPolicy: Never
      nodeSelector:
        kubernetes.io/hostname: "{{ client_node.name }}"
      containers:
      - name: deepep-internode-worker
        image: {{ image }}
        command: ["/bin/bash"]
        args:
        - -c
        - |
          set -e
          echo "Starting DeepEP internode test (WORKER) on node {{ client_node.name }}"

          echo "GPU information:"
          nvidia-smi -L

          GPU_COUNT=$(nvidia-smi -L | wc -l)
          echo "Detected $GPU_COUNT GPUs"

          echo "Cloning DeepEP repository..."
          cd /tmp
          git clone https://github.com/deepseek-ai/DeepEP || echo "Repository already exists"
          cd DeepEP

          echo "Waiting for master to be ready..."
          until getent hosts deepep-internode-master-{{ test_id }}; do
            echo "Waiting for master service..."
            sleep 2
          done
          sleep 5

          echo "Running DeepEP internode test with $GPU_COUNT processes per node, 2 nodes total..."
          export MASTER_ADDR=deepep-internode-master-{{ test_id }}
          export MASTER_PORT=29500
          export WORLD_SIZE=2

          python tests/test_internode.py --num-processes $GPU_COUNT --num-tokens 512 --hidden 1024 --num-topk 4 --num-experts 32

          echo "DeepEP internode test completed successfully"
        resources:
          requests:
            {{ rdma_resource_type }}: "1"
            nvidia.com/gpu: "{{ gpu_count }}"
            memory: 32Gi
            cpu: "16"
          limits:
            {{ rdma_resource_type }}: "1"
            nvidia.com/gpu: "{{ gpu_count }}"
            memory: 64Gi
            cpu: "32"
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
