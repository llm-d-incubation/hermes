---
apiVersion: v1
kind: Service
metadata:
  name: pplx-kernels-master-{{ test_id }}
  labels:
    app: pplx-kernels-test
    test-id: "{{ test_id }}"
spec:
  clusterIP: None
  selector:
    app: pplx-kernels-test
    role: master
    test-id: "{{ test_id }}"
  ports:
  - port: 29500
    name: dist
---
apiVersion: batch/v1
kind: Job
metadata:
  name: pplx-kernels-master-{{ test_id }}
  labels:
    app: pplx-kernels-test
    role: master
    test-id: "{{ test_id }}"
spec:
  template:
    metadata:
      labels:
        app: pplx-kernels-test
        role: master
        test-id: "{{ test_id }}"
    spec:
      restartPolicy: Never
      nodeSelector:
        kubernetes.io/hostname: "{{ server_node.name }}"
      containers:
      - name: pplx-kernels-master
        image: {{ image }}
        command: ["/bin/bash"]
        args:
        - -c
        - |
          set -e
          echo "Starting pplx-kernels all-to-all benchmark (MASTER) on node {{ server_node.name }}"

          echo "GPU information:"
          nvidia-smi -L

          GPU_COUNT=$(nvidia-smi -L | wc -l)
          echo "Detected $GPU_COUNT GPUs"

          echo "Cloning pplx-kernels repository..."
          cd /tmp
          git clone https://github.com/perplexityai/pplx-kernels.git || echo "Repository already exists"
          cd pplx-kernels

          echo "Installing pytest to /tmp..."
          pip install --target=/tmp pytest --quiet
          export PYTHONPATH=/tmp:$PYTHONPATH

          TOTAL_GPUS=$((GPU_COUNT * 2))
          DP_SIZE=1
          echo "Running all-to-all benchmark with world-size=$TOTAL_GPUS dp-size=$DP_SIZE (rank 0-$((GPU_COUNT-1)))"

          export MASTER_ADDR=pplx-kernels-master-{{ test_id }}
          export MASTER_PORT=29500
          export WORLD_SIZE=$TOTAL_GPUS
          export WORLD_LOCAL_SIZE=$GPU_COUNT
          export NODE_RANK=0
          export RANK=0
          export LOCAL_RANK=0

          python -m tests.bench_all_to_all --dp-size $DP_SIZE

          echo "pplx-kernels benchmark completed successfully"
        resources:
          requests:
            {{ rdma_resource_type }}: "1"
            nvidia.com/gpu: "1"
            memory: 8Gi
            cpu: "4"
          limits:
            {{ rdma_resource_type }}: "1"
            nvidia.com/gpu: "1"
            memory: 16Gi
            cpu: "8"
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
---
apiVersion: batch/v1
kind: Job
metadata:
  name: pplx-kernels-worker-{{ test_id }}
  labels:
    app: pplx-kernels-test
    role: worker
    test-id: "{{ test_id }}"
spec:
  template:
    metadata:
      labels:
        app: pplx-kernels-test
        role: worker
        test-id: "{{ test_id }}"
    spec:
      restartPolicy: Never
      nodeSelector:
        kubernetes.io/hostname: "{{ client_node.name }}"
      containers:
      - name: pplx-kernels-worker
        image: {{ image }}
        command: ["/bin/bash"]
        args:
        - -c
        - |
          set -e
          echo "Starting pplx-kernels all-to-all benchmark (WORKER) on node {{ client_node.name }}"

          echo "GPU information:"
          nvidia-smi -L

          GPU_COUNT=$(nvidia-smi -L | wc -l)
          echo "Detected $GPU_COUNT GPUs"

          echo "Cloning pplx-kernels repository..."
          cd /tmp
          git clone https://github.com/perplexityai/pplx-kernels.git || echo "Repository already exists"
          cd pplx-kernels

          echo "Installing pytest to /tmp..."
          pip install --target=/tmp pytest --quiet
          export PYTHONPATH=/tmp:$PYTHONPATH

          echo "Waiting for master to be ready..."
          until getent hosts pplx-kernels-master-{{ test_id }}; do
            echo "Waiting for master service..."
            sleep 2
          done
          sleep 5

          TOTAL_GPUS=$((GPU_COUNT * 2))
          DP_SIZE=1
          echo "Running all-to-all benchmark with world-size=$TOTAL_GPUS dp-size=$DP_SIZE (rank $GPU_COUNT-$((TOTAL_GPUS-1)))"

          export MASTER_ADDR=pplx-kernels-master-{{ test_id }}
          export MASTER_PORT=29500
          export WORLD_SIZE=$TOTAL_GPUS
          export WORLD_LOCAL_SIZE=$GPU_COUNT
          export NODE_RANK=1
          export RANK=$GPU_COUNT
          export LOCAL_RANK=0

          python -m tests.bench_all_to_all --dp-size $DP_SIZE

          echo "pplx-kernels benchmark completed successfully"
        resources:
          requests:
            {{ rdma_resource_type }}: "1"
            nvidia.com/gpu: "1"
            memory: 8Gi
            cpu: "4"
          limits:
            {{ rdma_resource_type }}: "1"
            nvidia.com/gpu: "1"
            memory: 16Gi
            cpu: "8"
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
